{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1Noe_tM2wAj",
    "colab_type": "text"
   },
   "source": [
    "# ANN classifiers for German noun genders\n",
    "\n",
    "Noun data and gender extraction method using <https://github.com/karoly-varasdi/de-wiktionary-parser>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F23wYXRW2wAm",
    "colab_type": "code",
    "outputId": "84c740da-691e-4e08-d38a-edb3f90e6b27",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'de-wiktionary-parser'...\n",
      "remote: Enumerating objects: 120, done.\u001b[K\n",
      "remote: Total 120 (delta 0), reused 0 (delta 0), pack-reused 120\u001b[K\n",
      "Receiving objects: 100% (120/120), 25.99 MiB | 41.65 MiB/s, done.\n",
      "Resolving deltas: 100% (42/42), done.\n",
      "Processing ./de-wiktionary-parser/dist/dewiktionaryparser-1.1.1.tar.gz\n",
      "Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (from dewiktionaryparser==1.1.1) (1.35)\n",
      "Collecting prettytable (from dewiktionaryparser==1.1.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
      "Building wheels for collected packages: dewiktionaryparser, prettytable\n",
      "  Running setup.py bdist_wheel for dewiktionaryparser ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/68/af/60/cd966fa9ccc8dd8735fa850151560574069d3e9f40103713c3\n",
      "  Running setup.py bdist_wheel for prettytable ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
      "Successfully built dewiktionaryparser prettytable\n",
      "Installing collected packages: prettytable, dewiktionaryparser\n",
      "Successfully installed dewiktionaryparser-1.1.1 prettytable-0.7.2\n"
     ]
    }
   ],
   "source": [
    "## to install dewiktionaryparser:\n",
    "!git clone https://github.com/karoly-varasdi/de-wiktionary-parser\n",
    "!pip install de-wiktionary-parser/dist/dewiktionaryparser-1.1.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0YAlAnjl2wAs",
    "colab_type": "code",
    "outputId": "e6fb112e-ab94-415a-9798-0bd4219d762b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## packages for dataset preparation\n",
    "import dewiktionaryparser as dw\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy import NaN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "## packages for NN training\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.optimizers\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sNJ9XXA2wA3",
    "colab_type": "text"
   },
   "source": [
    "## Creating the dataset\n",
    "\n",
    "Loading DE wiktionary info on common nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0lpJe1p72wA6",
    "colab_type": "code",
    "outputId": "ea2a7375-2293-407f-a787-350d55edc33c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving dictionary from ./data/de_noun_entries_commons.json . . .\n",
      "Retrieved 69558 entries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipfile.ZipFile('de-wiktionary-parser/data/de_noun_entries_commons.zip').extractall('data')\n",
    "commons = dw.GermanNounEntriesDict()\n",
    "commons.retrieve_from_json(r'./data/de_noun_entries_commons.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z2H_DMEq3SK-",
    "colab_type": "code",
    "outputId": "9f210d05-29d2-4a66-fb2a-a20ab8b7ee89",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  de-wiktionary-parser  sample_data\n",
      "de_noun_entries_commons.json\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsZLIhqO2wBC",
    "colab_type": "text"
   },
   "source": [
    "### One-hot encode gender information for nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "H1Dh-P5y2wBD",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def gender_onehot_encode(noundic):\n",
    "    '''One-hot encode gender information for nouns; takes a dewiktionary dictionary and \n",
    "    returns a dictionary of noun: [m, f, n] items\n",
    "    such that each value is a 3-place list, where 0 means the noun does not have that gender\n",
    "    and 1 means that it does.\n",
    "    E.g., {'Katze': [0, 1, 0]}'''\n",
    "    \n",
    "    genderdic = {'m': 0, 'f': 1, 'n': 2}\n",
    "    nounsandgenders = {}\n",
    "    nounswithnogenders = []\n",
    "    \n",
    "    print(\"\\nCollecting gender information...\")\n",
    "    counter = 0\n",
    "    for noun in noundic:\n",
    "        counter += 1\n",
    "        for gender in genderdic:\n",
    "            if gender in ''.join(sorted(set(dw.explore.genders(noun, noundic)))):\n",
    "                # set the index of that gender in the noun entry for nounsandgenders to 1 from 0\n",
    "                # e.g., for 'm' (index 0 in genderdic): [0, 0, 1] -> [1, 0, 1]\n",
    "                try:\n",
    "                    nounsandgenders[noun][genderdic[gender]] = 1\n",
    "                except KeyError:\n",
    "                    nounsandgenders.setdefault(noun, [0, 0, 0])\n",
    "                    nounsandgenders[noun][genderdic[gender]] = 1\n",
    "        if not noun in nounsandgenders:\n",
    "            nounswithnogenders.append(noun)\n",
    "    \n",
    "    print(\"Gender information from {} nouns collected.\\n\\\n",
    "        {} nouns with genders included.\\n\\\n",
    "        {} nouns with no genders omitted.\".format(counter, len(nounsandgenders), len(nounswithnogenders)))\n",
    "                    \n",
    "    return nounsandgenders\n",
    "        \n",
    "\n",
    "## In case we want to save dictionary info:\n",
    "def save_dic_to_csv(dic, path=r'.\\data\\dic.csv', encoding='utf-8'):\n",
    "    with open(path, 'w', encoding=encoding) as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in dic.items():\n",
    "           writer.writerow([key, value])\n",
    "    print(\"Dictionary saved successfully to {}.\".format(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y63EtZan2wBJ",
    "colab_type": "text"
   },
   "source": [
    "Generate gender info for German common nouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E0-7WvGC2wBK",
    "colab_type": "code",
    "outputId": "c3685156-c024-49a0-f562-6c534e40151f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting gender information...\n",
      "Gender information from 69558 nouns collected.\n",
      "        69272 nouns with genders included.\n",
      "        286 nouns with no genders omitted.\n"
     ]
    }
   ],
   "source": [
    "nounsandgenders = gender_onehot_encode(commons)\n",
    "# save_dic_to_csv(nounsandgenders, path=r'.\\data\\nounsandgenders.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCm3i0bCfkFc",
    "colab_type": "text"
   },
   "source": [
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N56LkU9a2wBR",
    "colab_type": "code",
    "outputId": "1e44f63a-e92e-40f9-f98c-582e8ad2822d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[male, female, neuter] genders in wiktionary for 'Reis':\n",
      " m, f, n\n",
      "[1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"[male, female, neuter] genders in wiktionary for 'Reis':\\n m, f, n\\n{}\".format(nounsandgenders['Reis']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EPKEV2lRGtZi",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    },
    "outputId": "c79b8ead-521d-4a91-98f2-ba790c5aaaf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(nounsandgenders['Bild'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZtWY_0Y2wBY",
    "colab_type": "text"
   },
   "source": [
    "### Create character-to-integer encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39OqBqQ22wBa",
    "colab_type": "text"
   },
   "source": [
    "#### Collect all characters in common nouns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "AhyJcuzd2wBb",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def collect_chars(dic):\n",
    "    '''Takes a dictionary whose keys are strings and returns the set of all characters \n",
    "    used in them as a sorted list.'''\n",
    "    chars = set()\n",
    "    print(\"\\nCollecting characters...\")\n",
    "    for word in dic:\n",
    "        for char in word:\n",
    "            chars.add(char)\n",
    "    print(\"{} characters collected.\".format(len(chars)))\n",
    "    return sorted(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RGKLfJVs2wBg",
    "colab_type": "code",
    "outputId": "946df0a5-ea53-422e-ff81-2eef6dd295d4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting characters...\n",
      "113 characters collected.\n"
     ]
    }
   ],
   "source": [
    "nounchars = collect_chars(nounsandgenders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWq8crdY2wBl",
    "colab_type": "text"
   },
   "source": [
    "#### Integer encoder for characters from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jqZPd92L2wBp",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70.0
    },
    "outputId": "1a8ca6f7-2bfb-4837-c579-760995fc3e29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# encode characters occurring in common nouns as integers \n",
    "char_encoder = LabelEncoder()\n",
    "integer_encoded_chars = char_encoder.fit_transform(nounchars)\n",
    "\n",
    "# ordered list of characters, with index corresponding to integer label:\n",
    "char_list = list(char_encoder.inverse_transform(range(len(nounchars))))\n",
    "\n",
    "# only for our information, create a character-integer dictionary\n",
    "char_dic = {c: char_encoder.transform([c])[0] for c in nounchars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2Osjg8d_2wBw",
    "colab_type": "code",
    "outputId": "f83d2fd2-4987-4f8b-9a17-da809461d682",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '&': 1, \"'\": 2, ',': 3, '-': 4, '.': 5, '/': 6, '0': 7, '1': 8, '2': 9, '3': 10, '4': 11, '5': 12, '6': 13, '7': 14, '8': 15, '9': 16, 'A': 17, 'B': 18, 'C': 19, 'D': 20, 'E': 21, 'F': 22, 'G': 23, 'H': 24, 'I': 25, 'J': 26, 'K': 27, 'L': 28, 'M': 29, 'N': 30, 'O': 31, 'P': 32, 'Q': 33, 'R': 34, 'S': 35, 'T': 36, 'U': 37, 'V': 38, 'W': 39, 'X': 40, 'Y': 41, 'Z': 42, 'a': 43, 'b': 44, 'c': 45, 'd': 46, 'e': 47, 'f': 48, 'g': 49, 'h': 50, 'i': 51, 'j': 52, 'k': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'q': 59, 'r': 60, 's': 61, 't': 62, 'u': 63, 'v': 64, 'w': 65, 'x': 66, 'y': 67, 'z': 68, 'À': 69, 'Ä': 70, 'Å': 71, 'É': 72, 'Ö': 73, 'Ü': 74, 'ß': 75, 'à': 76, 'á': 77, 'â': 78, 'ã': 79, 'ä': 80, 'å': 81, 'ç': 82, 'è': 83, 'é': 84, 'ê': 85, 'í': 86, 'ï': 87, 'ñ': 88, 'ó': 89, 'ô': 90, 'õ': 91, 'ö': 92, 'ú': 93, 'û': 94, 'ü': 95, 'ā': 96, 'č': 97, 'ē': 98, 'ī': 99, 'ł': 100, 'ō': 101, 'Œ': 102, 'œ': 103, 'Š': 104, 'ū': 105, 'ǃ': 106, 'ǧ': 107, 'α': 108, 'β': 109, 'γ': 110, 'Ḫ': 111, '’': 112}\n"
     ]
    }
   ],
   "source": [
    "# the character-ingeter dictionary\n",
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeyqikRtJAwa",
    "colab_type": "text"
   },
   "source": [
    "A sample encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bkYq28FQ2wB2",
    "colab_type": "code",
    "outputId": "c8807572-52a5-442c-bf9b-b0bb5e12941f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 43, 54, 54, 57])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_encoder.transform(['H', 'a', 'l', 'l', 'o'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HazplpTOIUgz",
    "colab_type": "text"
   },
   "source": [
    "Some nouns with weird characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TjwJad2sH_nN",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84.0
    },
    "outputId": "9ae67f00-64b2-433c-93a1-00b295726555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β-Ketobuttersäure\n",
      "Kyū\n",
      "ǃXóõ\n",
      "Ḫāriǧit\n"
     ]
    }
   ],
   "source": [
    "for noun in nounsandgenders:\n",
    "    if 'Ḫ' in noun or 'β' in noun or 'ǃ' in noun or 'ū' in noun:\n",
    "        print(noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTsNnuZY2wB8",
    "colab_type": "text"
   },
   "source": [
    "### Creating dataframe with the features to be used by the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VLC5HPgc2wB-",
    "colab_type": "code",
    "outputId": "62d95271-f4aa-421f-a2f6-fecdba6dd5e4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating df with info on gender...\n",
      "Adding information on last 4 characters (this can take a while)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>4_</th>\n",
       "      <th>4_&amp;</th>\n",
       "      <th>4_'</th>\n",
       "      <th>4_,</th>\n",
       "      <th>4_-</th>\n",
       "      <th>4_.</th>\n",
       "      <th>4_/</th>\n",
       "      <th>...</th>\n",
       "      <th>1_œ</th>\n",
       "      <th>1_Š</th>\n",
       "      <th>1_ū</th>\n",
       "      <th>1_ǃ</th>\n",
       "      <th>1_ǧ</th>\n",
       "      <th>1_α</th>\n",
       "      <th>1_β</th>\n",
       "      <th>1_γ</th>\n",
       "      <th>1_Ḫ</th>\n",
       "      <th>1_’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hallo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subfamilia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subregnum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subdivisio</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phylum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            m  f  n  4_   4_&  4_'  4_,  4_-  4_.  4_/ ...   1_œ  1_Š  1_ū  \\\n",
       "Hallo       0  0  1    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "Subfamilia  0  1  0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "Subregnum   0  0  1    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "Subdivisio  0  1  0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "Phylum      0  0  1    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "\n",
       "            1_ǃ  1_ǧ  1_α  1_β  1_γ  1_Ḫ  1_’  \n",
       "Hallo         0    0    0    0    0    0    0  \n",
       "Subfamilia    0    0    0    0    0    0    0  \n",
       "Subregnum     0    0    0    0    0    0    0  \n",
       "Subdivisio    0    0    0    0    0    0    0  \n",
       "Phylum        0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 455 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating df with info on gender...\")\n",
    "# get gender information from nounsandgenders\n",
    "df = pd.DataFrame.from_dict(nounsandgenders, \n",
    "                            orient='index', \n",
    "#                            columns=['m', 'f', 'n']\n",
    "                           )\n",
    "df.columns = ['m', 'f', 'n']\n",
    "\n",
    "# Now get the last 4 characters and encode for each possible character whether it is the character in the relevant position.\n",
    "print(\"Adding information on last 4 characters (this can take a while)...\")\n",
    "\n",
    "def is_char_in_pos(char, pos, noun):\n",
    "    '''Returns 1 if char in position in noun, else 0'''\n",
    "    val = 0\n",
    "    try:\n",
    "        if noun[pos] == char:\n",
    "            val = 1\n",
    "    except IndexError:\n",
    "        pass\n",
    "    return val\n",
    "        \n",
    "# We iterate through each of the last 4 positions.\n",
    "for pos in range(4, 0, -1):\n",
    "    # and we iterate through all characters used in common nouns\n",
    "    for char in char_list:\n",
    "        # create a new column for the (pos, char) pair and for each noun, assign 0 or 1 to it\n",
    "        df[str(pos) + '_' + str(char)] = [is_char_in_pos(char, -1 * pos, noun) for noun in df.index.format()]\n",
    "        #df[str(pos) + '_' + str(char)] = [1 if len(i) >= abs(pos) and i[pos] == char else 0 for i in df.index.format()]\n",
    "    \n",
    "\n",
    "# the first five entries\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wPQdcGYG2wCD",
    "colab_type": "code",
    "outputId": "1f44f6d9-d821-48f2-8fdb-d1d667eba824",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 78.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>4_</th>\n",
       "      <th>4_&amp;</th>\n",
       "      <th>4_'</th>\n",
       "      <th>4_,</th>\n",
       "      <th>4_-</th>\n",
       "      <th>4_.</th>\n",
       "      <th>4_/</th>\n",
       "      <th>...</th>\n",
       "      <th>1_œ</th>\n",
       "      <th>1_Š</th>\n",
       "      <th>1_ū</th>\n",
       "      <th>1_ǃ</th>\n",
       "      <th>1_ǧ</th>\n",
       "      <th>1_α</th>\n",
       "      <th>1_β</th>\n",
       "      <th>1_γ</th>\n",
       "      <th>1_Ḫ</th>\n",
       "      <th>1_’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [m, f, n, 4_ , 4_&, 4_', 4_,, 4_-, 4_., 4_/, 4_0, 4_1, 4_2, 4_3, 4_4, 4_5, 4_6, 4_7, 4_8, 4_9, 4_A, 4_B, 4_C, 4_D, 4_E, 4_F, 4_G, 4_H, 4_I, 4_J, 4_K, 4_L, 4_M, 4_N, 4_O, 4_P, 4_Q, 4_R, 4_S, 4_T, 4_U, 4_V, 4_W, 4_X, 4_Y, 4_Z, 4_a, 4_b, 4_c, 4_d, 4_e, 4_f, 4_g, 4_h, 4_i, 4_j, 4_k, 4_l, 4_m, 4_n, 4_o, 4_p, 4_q, 4_r, 4_s, 4_t, 4_u, 4_v, 4_w, 4_x, 4_y, 4_z, 4_À, 4_Ä, 4_Å, 4_É, 4_Ö, 4_Ü, 4_ß, 4_à, 4_á, 4_â, 4_ã, 4_ä, 4_å, 4_ç, 4_è, 4_é, 4_ê, 4_í, 4_ï, 4_ñ, 4_ó, 4_ô, 4_õ, 4_ö, 4_ú, 4_û, 4_ü, 4_ā, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 455 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check that no rows have NaNs\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdyD-BBv2wCL",
    "colab_type": "text"
   },
   "source": [
    "#### Add syllable count information\n",
    "\n",
    "* Note that **digraphs** come first in the regex pattern so that they are counted as one.\n",
    "* Note that this syllable count is only an approximation, as \"ie\" sometimes stands for 2 syllables (\"*Familie*\"), sometimes 1 (\"*Allergie*\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Oc9RfP1R2wCN",
    "colab_type": "code",
    "outputId": "b63b80c3-7d17-4662-cfc9-cb8e7e14a3d0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>4_</th>\n",
       "      <th>4_&amp;</th>\n",
       "      <th>4_'</th>\n",
       "      <th>4_,</th>\n",
       "      <th>4_-</th>\n",
       "      <th>4_.</th>\n",
       "      <th>4_/</th>\n",
       "      <th>...</th>\n",
       "      <th>1_Š</th>\n",
       "      <th>1_ū</th>\n",
       "      <th>1_ǃ</th>\n",
       "      <th>1_ǧ</th>\n",
       "      <th>1_α</th>\n",
       "      <th>1_β</th>\n",
       "      <th>1_γ</th>\n",
       "      <th>1_Ḫ</th>\n",
       "      <th>1_’</th>\n",
       "      <th>syll-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hallo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subfamilia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subregnum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subdivisio</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phylum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            m  f  n  4_   4_&  4_'  4_,  4_-  4_.  4_/     ...      1_Š  1_ū  \\\n",
       "Hallo       0  0  1    0    0    0    0    0    0    0     ...        0    0   \n",
       "Subfamilia  0  1  0    0    0    0    0    0    0    0     ...        0    0   \n",
       "Subregnum   0  0  1    0    0    0    0    0    0    0     ...        0    0   \n",
       "Subdivisio  0  1  0    0    0    0    0    0    0    0     ...        0    0   \n",
       "Phylum      0  0  1    0    0    0    0    0    0    0     ...        0    0   \n",
       "\n",
       "            1_ǃ  1_ǧ  1_α  1_β  1_γ  1_Ḫ  1_’  syll-count  \n",
       "Hallo         0    0    0    0    0    0    0           2  \n",
       "Subfamilia    0    0    0    0    0    0    0           5  \n",
       "Subregnum     0    0    0    0    0    0    0           3  \n",
       "Subdivisio    0    0    0    0    0    0    0           5  \n",
       "Phylum        0    0    0    0    0    0    0           2  \n",
       "\n",
       "[5 rows x 456 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the syllabic vowels/vowel combinations in German\n",
    "vowelregex = re.compile(r\"(aa|ee|ie|oo|au|eu|äu|ei|ai|ey|ay|a|ä|e|i|o|ö|u|ü|y)\")\n",
    "\n",
    "# adding syllable count informatoin\n",
    "df['syll-count'] = [len(re.findall(vowelregex, noun.lower())) for noun in df.index.format()]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYX19wa_a2ZH",
    "colab_type": "text"
   },
   "source": [
    "The first 5 samples with only the columns with nonnull values for any of them showing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VQW9zN9sRrcL",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201.0
    },
    "outputId": "b503e278-ed55-4302-b501-b91dc36609eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>4_a</th>\n",
       "      <th>4_g</th>\n",
       "      <th>4_i</th>\n",
       "      <th>4_y</th>\n",
       "      <th>3_l</th>\n",
       "      <th>3_n</th>\n",
       "      <th>3_s</th>\n",
       "      <th>2_i</th>\n",
       "      <th>2_l</th>\n",
       "      <th>2_u</th>\n",
       "      <th>1_a</th>\n",
       "      <th>1_m</th>\n",
       "      <th>1_o</th>\n",
       "      <th>syll-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hallo</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subfamilia</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subregnum</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subdivisio</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phylum</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f  n  4_a  4_g  4_i  4_y  3_l  3_n  3_s  2_i  2_l  2_u  1_a  1_m  \\\n",
       "Hallo       0  1    1    0    0    0    1    0    0    0    1    0    0    0   \n",
       "Subfamilia  1  0    0    0    1    0    1    0    0    1    0    0    1    0   \n",
       "Subregnum   0  1    0    1    0    0    0    1    0    0    0    1    0    1   \n",
       "Subdivisio  1  0    0    0    1    0    0    0    1    1    0    0    0    0   \n",
       "Phylum      0  1    0    0    0    1    1    0    0    0    0    1    0    1   \n",
       "\n",
       "            1_o  syll-count  \n",
       "Hallo         1           2  \n",
       "Subfamilia    0           5  \n",
       "Subregnum     0           3  \n",
       "Subdivisio    1           5  \n",
       "Phylum        0           2  "
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().loc[:,(df.head() != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z10Ll3nN2wCf",
    "colab_type": "text"
   },
   "source": [
    "### To export the dataframe into a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-wjr6imD2wCg",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# df.to_csv(r'.\\data\\allnoungenderdf.csv', encoding='utf-8')\n",
    "# print(\"allnoungenderdf.csv saved successfully in data folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTuu-k3Z2wAx",
    "colab_type": "text"
   },
   "source": [
    "## Setting the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvZn0oa6QBXg",
    "colab_type": "text"
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XqZE5UWyQArO",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "## can be used as keras model metrics\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    '''The average predicted value'''\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\n",
    "## precision and recall definitions from older verion of keras\n",
    "## https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "def precision(y_true, y_pred):\n",
    "\t\"\"\"Precision metric.\n",
    "\tOnly computes a batch-wise average of precision.\n",
    "\tComputes the precision, a metric for multi-label classification of\n",
    "\thow many selected items are relevant.\n",
    "\t\"\"\"\n",
    "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\tpredicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\tprecision = true_positives / (predicted_positives + K.epsilon())\n",
    "\treturn precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "\t\"\"\"Recall metric.\n",
    "\tOnly computes a batch-wise average of recall.\n",
    "\tComputes the recall, a metric for multi-label classification of\n",
    "\thow many relevant items are selected.\n",
    "\t\"\"\"\n",
    "\ttrue_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "\tpossible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\trecall = true_positives / (possible_positives + K.epsilon())\n",
    "\treturn recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "\t\"\"\"Computes the F score.\n",
    "\tThe F score is the weighted harmonic mean of precision and recall.\n",
    "\tHere it is only computed as a batch-wise average, not globally.\n",
    "\tThis is useful for multi-label classification, where input samples can be\n",
    "\tclassified as sets of labels. By only using accuracy (precision) a model\n",
    "\twould achieve a perfect score by simply assigning every class to every\n",
    "\tinput. In order to avoid this, a metric should penalize incorrect class\n",
    "\tassignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "\tcomputes this, as a weighted mean of the proportion of correct class\n",
    "\tassignments vs. the proportion of incorrect class assignments.\n",
    "\tWith beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "\tcorrect classes becomes more important, and with beta > 1 the metric is\n",
    "\tinstead weighted towards penalizing incorrect class assignments.\n",
    "\t\"\"\"\n",
    "\tif beta < 0:\n",
    "\t\traise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\t# If there are no true positives, fix the F score at 0 like sklearn.\n",
    "\tif K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "\t\treturn 0\n",
    "\tp = precision(y_true, y_pred)\n",
    "\tr = recall(y_true, y_pred)\n",
    "\tbb = beta ** 2\n",
    "\tfbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "\treturn fbeta_score\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "\t\"\"\"Computes the f-measure, the harmonic mean of precision and recall.\n",
    "\tHere it is only computed as a batch-wise average, not globally.\n",
    "\t\"\"\"\n",
    "\treturn fbeta_score(y_true, y_pred, beta=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOgtgSMXQ59X",
    "colab_type": "text"
   },
   "source": [
    "#### The parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vJTT-Mmu2wAz",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "hidden_layer_1_nodes = 200\n",
    "hidden_layer_2_nodes = 60\n",
    "\n",
    "activation_hidden_1 = 'relu'\n",
    "activation_hidden_2 = 'relu'\n",
    "activation_output = 'sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "# loss='mean_squared_error'\n",
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "## (The default value for learning rate for stochastic gradient descent is 0.01)\n",
    "optimizer='adadelta'\n",
    "\n",
    "## since this is a binary categorisation test, 'accuracy' is here equal to 'binary_accuracy' (predicted value >= 0.5 equals 1)\n",
    "metrics=['accuracy', precision, recall, fmeasure]\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 20\n",
    "\n",
    "#sample_size = len(df)\n",
    "sample_size = 20000\n",
    "# 10% of the sample_size will be used for testing, 90% for training\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 5\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nBub7Zk2wCt",
    "colab_type": "text"
   },
   "source": [
    "## Loading the dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "E_az_Pxa2wCw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# if load from file\n",
    "# df = pd.read_csv(r'.\\data\\allnoungenderdf.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nKshqfKE2wC0",
    "colab_type": "code",
    "outputId": "80c68000-d5b3-44b3-e4b9-b80fea30994b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ngtrain items:18000\n",
      "Number of ngtest items:2000\n",
      "\n",
      "First 5 ngtrain items:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>f</th>\n",
       "      <th>n</th>\n",
       "      <th>4_</th>\n",
       "      <th>4_&amp;</th>\n",
       "      <th>4_'</th>\n",
       "      <th>4_,</th>\n",
       "      <th>4_-</th>\n",
       "      <th>4_.</th>\n",
       "      <th>4_/</th>\n",
       "      <th>...</th>\n",
       "      <th>1_Š</th>\n",
       "      <th>1_ū</th>\n",
       "      <th>1_ǃ</th>\n",
       "      <th>1_ǧ</th>\n",
       "      <th>1_α</th>\n",
       "      <th>1_β</th>\n",
       "      <th>1_γ</th>\n",
       "      <th>1_Ḫ</th>\n",
       "      <th>1_’</th>\n",
       "      <th>syll-count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abzweig</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abgasmanipulation</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kolonialimperium</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Käuferin</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Busfahrer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   m  f  n  4_   4_&  4_'  4_,  4_-  4_.  4_/     ...      \\\n",
       "Abzweig            1  0  0    0    0    0    0    0    0    0     ...       \n",
       "Abgasmanipulation  0  1  0    0    0    0    0    0    0    0     ...       \n",
       "Kolonialimperium   0  0  1    0    0    0    0    0    0    0     ...       \n",
       "Käuferin           0  1  0    0    0    0    0    0    0    0     ...       \n",
       "Busfahrer          1  0  0    0    0    0    0    0    0    0     ...       \n",
       "\n",
       "                   1_Š  1_ū  1_ǃ  1_ǧ  1_α  1_β  1_γ  1_Ḫ  1_’  syll-count  \n",
       "Abzweig              0    0    0    0    0    0    0    0    0           2  \n",
       "Abgasmanipulation    0    0    0    0    0    0    0    0    0           8  \n",
       "Kolonialimperium     0    0    0    0    0    0    0    0    0           8  \n",
       "Käuferin             0    0    0    0    0    0    0    0    0           3  \n",
       "Busfahrer            0    0    0    0    0    0    0    0    0           3  \n",
       "\n",
       "[5 rows x 456 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select randomly items for training and testing\n",
    "ngtrain = df.sample(sample_size, random_state = seed)\n",
    "# select 10% of these as test items, keep the rest as training data\n",
    "ngtest = ngtrain.sample(frac = .1, random_state = seed)\n",
    "# now delete the test data from the training data\n",
    "ngtrain = ngtrain.drop(ngtest.index)\n",
    "\n",
    "# convert pandas dataframes into numpy arrays for the model to use:\n",
    "#ngtrain = ngtrain.values\n",
    "#ngtest = ngtest.values\n",
    "\n",
    "\n",
    "print(\"Number of ngtrain items:{}\".format(len(ngtrain)))\n",
    "print(\"Number of ngtest items:{}\".format(len(ngtest)))\n",
    "\n",
    "print(\"\\nFirst 5 ngtrain items:\\n\")\n",
    "ngtrain[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "AxD0kCXl2wDC",
    "colab_type": "code",
    "outputId": "80505557-8c8e-4ea9-cb68-ad302a1f166c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input data:\t(18000, 453)\n",
      "Shape of male, female, neuter output data:\t(18000,), (18000,), (18000,)\n",
      "\n",
      "Shape of input test data:\t(2000, 453)\n",
      "Shape of male, female, neuter output test data:\t(2000,), (2000,), (2000,)\n"
     ]
    }
   ],
   "source": [
    "# create input and output as numpy arrays\n",
    "# Columns 0, 1, 2 are gender info = output, the rest are the features = input\n",
    "input_train = ngtrain.values[:,3:]\n",
    "output_train_m = ngtrain.values[:,0]\n",
    "output_train_f = ngtrain.values[:,1]\n",
    "output_train_n = ngtrain.values[:,2]\n",
    "input_test = ngtest.values[:,3:]\n",
    "output_test_m = ngtest.values[:,0]\n",
    "output_test_f = ngtest.values[:,1]\n",
    "output_test_n = ngtest.values[:,2]\n",
    "\n",
    "print(\"Shape of input data:\\t{}\".format(np.shape(input_train)))\n",
    "print(\"Shape of male, female, neuter output data:\\t{}, {}, {}\".format(np.shape(output_train_m), np.shape(output_train_f), np.shape(output_train_n)))\n",
    "\n",
    "print(\"\\nShape of input test data:\\t{}\".format(np.shape(input_test)))\n",
    "print(\"Shape of male, female, neuter output test data:\\t{}, {}, {}\".format(np.shape(output_test_m), np.shape(output_test_f), np.shape(output_test_n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nu3Y-5LQ2wDJ",
    "colab_type": "code",
    "outputId": "9f6e097f-dccf-466e-d6cb-b742701029db",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 2],\n",
       "       [0, 0, 0, ..., 0, 0, 8],\n",
       "       [0, 0, 0, ..., 0, 0, 8],\n",
       "       [0, 0, 0, ..., 0, 0, 3],\n",
       "       [0, 0, 0, ..., 0, 0, 3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-7ySh4cp2wDN",
    "colab_type": "code",
    "outputId": "08a1743e-2209-4601-ecdf-f69ae164260d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_train_m[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdE-sw7X2wDS",
    "colab_type": "text"
   },
   "source": [
    "## Creating the m, f, n gender classifier models\n",
    "\n",
    "Input dimensions: 4 * 113 + 1 = 453 = `len(input_train[0])`\n",
    "\n",
    "Output: 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "koJBzEgk2wDS",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model_m = Sequential()\n",
    "model_m.add(Dense(hidden_layer_1_nodes, input_dim=len(input_train[0]), \n",
    "                activation=activation_hidden_1))\n",
    "model_m.add(Dense(hidden_layer_2_nodes,\n",
    "                activation=activation_hidden_2))\n",
    "model_m.add(Dense(1, activation=activation_output))\n",
    "\n",
    "# compile the model\n",
    "model_m.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "hfxNEv7tgdPG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model_f = Sequential()\n",
    "model_f.add(Dense(hidden_layer_1_nodes, input_dim=len(input_train[0]), \n",
    "                activation=activation_hidden_1))\n",
    "model_f.add(Dense(hidden_layer_2_nodes,\n",
    "                activation=activation_hidden_2))\n",
    "model_f.add(Dense(1, activation=activation_output))\n",
    "\n",
    "# compile the model\n",
    "model_f.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0fTnq1wqge2p",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model_n = Sequential()\n",
    "model_n.add(Dense(hidden_layer_1_nodes, input_dim=len(input_train[0]), \n",
    "                activation=activation_hidden_1))\n",
    "model_n.add(Dense(hidden_layer_2_nodes,\n",
    "                activation=activation_hidden_2))\n",
    "model_n.add(Dense(1, activation=activation_output))\n",
    "\n",
    "# compile the model\n",
    "model_n.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzl7-MLT2wDV",
    "colab_type": "text"
   },
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MgoKJD1u2wDX",
    "colab_type": "code",
    "outputId": "86c5bf14-dac2-4354-ad34-1b31c50ce34f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.4580 - acc: 0.7800 - precision: 0.7078 - recall: 0.6929 - fmeasure: 0.6805\n",
      "Epoch 2/8\n",
      "18000/18000 [==============================] - 7s 393us/step - loss: 0.3587 - acc: 0.8366 - precision: 0.7918 - recall: 0.7838 - fmeasure: 0.7738\n",
      "Epoch 3/8\n",
      "18000/18000 [==============================] - 7s 392us/step - loss: 0.3143 - acc: 0.8641 - precision: 0.8316 - recall: 0.8051 - fmeasure: 0.8063\n",
      "Epoch 4/8\n",
      "18000/18000 [==============================] - 7s 394us/step - loss: 0.2882 - acc: 0.8775 - precision: 0.8517 - recall: 0.8237 - fmeasure: 0.8268\n",
      "Epoch 5/8\n",
      "18000/18000 [==============================] - 7s 393us/step - loss: 0.2706 - acc: 0.8877 - precision: 0.8672 - recall: 0.8404 - fmeasure: 0.8424\n",
      "Epoch 6/8\n",
      "18000/18000 [==============================] - 7s 393us/step - loss: 0.2570 - acc: 0.8950 - precision: 0.8734 - recall: 0.8511 - fmeasure: 0.8521\n",
      "Epoch 7/8\n",
      "18000/18000 [==============================] - 7s 392us/step - loss: 0.2458 - acc: 0.9007 - precision: 0.8772 - recall: 0.8588 - fmeasure: 0.8582\n",
      "Epoch 8/8\n",
      "18000/18000 [==============================] - 7s 389us/step - loss: 0.2377 - acc: 0.9033 - precision: 0.8822 - recall: 0.8613 - fmeasure: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f043e7865c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_m.fit(input_train, output_train_m, epochs=epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XsTTSm6fg2xs",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305.0
    },
    "outputId": "c9605a58-6583-4e05-ab23-b24a0fe1fd11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18000/18000 [==============================] - 7s 409us/step - loss: 0.3405 - acc: 0.8686 - precision: 0.8636 - recall: 0.8033 - fmeasure: 0.8203\n",
      "Epoch 2/8\n",
      "18000/18000 [==============================] - 7s 395us/step - loss: 0.2418 - acc: 0.9106 - precision: 0.9114 - recall: 0.8716 - fmeasure: 0.8838\n",
      "Epoch 3/8\n",
      "18000/18000 [==============================] - 7s 397us/step - loss: 0.2131 - acc: 0.9210 - precision: 0.9160 - recall: 0.8903 - fmeasure: 0.8971\n",
      "Epoch 4/8\n",
      "18000/18000 [==============================] - 7s 396us/step - loss: 0.1974 - acc: 0.9276 - precision: 0.9211 - recall: 0.9044 - fmeasure: 0.9070\n",
      "Epoch 5/8\n",
      "18000/18000 [==============================] - 7s 395us/step - loss: 0.1868 - acc: 0.9326 - precision: 0.9262 - recall: 0.9081 - fmeasure: 0.9119\n",
      "Epoch 6/8\n",
      "18000/18000 [==============================] - 7s 401us/step - loss: 0.1783 - acc: 0.9352 - precision: 0.9300 - recall: 0.9140 - fmeasure: 0.9170\n",
      "Epoch 7/8\n",
      "18000/18000 [==============================] - 7s 404us/step - loss: 0.1726 - acc: 0.9372 - precision: 0.9313 - recall: 0.9168 - fmeasure: 0.9188\n",
      "Epoch 8/8\n",
      "18000/18000 [==============================] - 7s 389us/step - loss: 0.1671 - acc: 0.9382 - precision: 0.9310 - recall: 0.9178 - fmeasure: 0.9195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f043e7864e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_f.fit(input_train, output_train_f, epochs=epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "brD-lxHig6M3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305.0
    },
    "outputId": "3f61cadd-ff82-47cb-ed90-948366bbdb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "18000/18000 [==============================] - 7s 407us/step - loss: 0.4115 - acc: 0.8136 - precision: 0.5161 - recall: 0.3162 - fmeasure: 0.3641\n",
      "Epoch 2/8\n",
      "18000/18000 [==============================] - 7s 387us/step - loss: 0.3278 - acc: 0.8616 - precision: 0.7300 - recall: 0.5570 - fmeasure: 0.6010\n",
      "Epoch 3/8\n",
      "18000/18000 [==============================] - 7s 390us/step - loss: 0.2886 - acc: 0.8808 - precision: 0.7673 - recall: 0.6306 - fmeasure: 0.6613\n",
      "Epoch 4/8\n",
      "18000/18000 [==============================] - 7s 394us/step - loss: 0.2648 - acc: 0.8914 - precision: 0.7917 - recall: 0.6748 - fmeasure: 0.7030\n",
      "Epoch 5/8\n",
      "18000/18000 [==============================] - 7s 391us/step - loss: 0.2485 - acc: 0.8979 - precision: 0.8100 - recall: 0.6942 - fmeasure: 0.7206\n",
      "Epoch 6/8\n",
      "18000/18000 [==============================] - 7s 393us/step - loss: 0.2356 - acc: 0.9066 - precision: 0.8160 - recall: 0.7173 - fmeasure: 0.7396\n",
      "Epoch 7/8\n",
      "18000/18000 [==============================] - 7s 391us/step - loss: 0.2248 - acc: 0.9093 - precision: 0.8191 - recall: 0.7339 - fmeasure: 0.7516\n",
      "Epoch 8/8\n",
      "18000/18000 [==============================] - 7s 390us/step - loss: 0.2164 - acc: 0.9135 - precision: 0.8265 - recall: 0.7429 - fmeasure: 0.7611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0437d26f60>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n.fit(input_train, output_train_n, epochs=epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq1ymnWRd1g8",
    "colab_type": "text"
   },
   "source": [
    "## Saving the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "MbfcY3rtd6Ih",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "## Save complete models (architecture, weights, traing config):\n",
    "# model_m.save(\"models/model_m.h5\")\n",
    "# model_f.save(\"models/model_f.h5\")\n",
    "# model_n.save(\"models/model_n.h5\")\n",
    "\n",
    "## Save only architecture\n",
    "model_arch = model_m.to_json()\n",
    "# model reconstruction from JSON:\n",
    "# new_model = model_from_json(model_arch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h2yxiC4fMpX",
    "colab_type": "text"
   },
   "source": [
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "koiRj3xjfMCy",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237.0
    },
    "outputId": "796add3c-5ad8-4175-9c30-fcc74ee62255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               90800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                12060     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 102,921\n",
      "Trainable params: 102,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_m.output_shape\n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "e_hGqqDWhVNn",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 984.0
    },
    "outputId": "42753110-3f01-4849-c141-37ef3c82f83a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers': [{'class_name': 'Dense',\n",
      "             'config': {'activation': 'relu',\n",
      "                        'activity_regularizer': None,\n",
      "                        'batch_input_shape': (None, 453),\n",
      "                        'bias_constraint': None,\n",
      "                        'bias_initializer': {'class_name': 'Zeros',\n",
      "                                             'config': {}},\n",
      "                        'bias_regularizer': None,\n",
      "                        'dtype': 'float32',\n",
      "                        'kernel_constraint': None,\n",
      "                        'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                                               'config': {'distribution': 'uniform',\n",
      "                                                          'mode': 'fan_avg',\n",
      "                                                          'scale': 1.0,\n",
      "                                                          'seed': None}},\n",
      "                        'kernel_regularizer': None,\n",
      "                        'name': 'dense_1',\n",
      "                        'trainable': True,\n",
      "                        'units': 200,\n",
      "                        'use_bias': True}},\n",
      "            {'class_name': 'Dense',\n",
      "             'config': {'activation': 'relu',\n",
      "                        'activity_regularizer': None,\n",
      "                        'bias_constraint': None,\n",
      "                        'bias_initializer': {'class_name': 'Zeros',\n",
      "                                             'config': {}},\n",
      "                        'bias_regularizer': None,\n",
      "                        'kernel_constraint': None,\n",
      "                        'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                                               'config': {'distribution': 'uniform',\n",
      "                                                          'mode': 'fan_avg',\n",
      "                                                          'scale': 1.0,\n",
      "                                                          'seed': None}},\n",
      "                        'kernel_regularizer': None,\n",
      "                        'name': 'dense_2',\n",
      "                        'trainable': True,\n",
      "                        'units': 60,\n",
      "                        'use_bias': True}},\n",
      "            {'class_name': 'Dense',\n",
      "             'config': {'activation': 'sigmoid',\n",
      "                        'activity_regularizer': None,\n",
      "                        'bias_constraint': None,\n",
      "                        'bias_initializer': {'class_name': 'Zeros',\n",
      "                                             'config': {}},\n",
      "                        'bias_regularizer': None,\n",
      "                        'kernel_constraint': None,\n",
      "                        'kernel_initializer': {'class_name': 'VarianceScaling',\n",
      "                                               'config': {'distribution': 'uniform',\n",
      "                                                          'mode': 'fan_avg',\n",
      "                                                          'scale': 1.0,\n",
      "                                                          'seed': None}},\n",
      "                        'kernel_regularizer': None,\n",
      "                        'name': 'dense_3',\n",
      "                        'trainable': True,\n",
      "                        'units': 1,\n",
      "                        'use_bias': True}}],\n",
      " 'name': 'sequential_1'}\n"
     ]
    }
   ],
   "source": [
    "model_m_weights = model_m.get_weights()\n",
    "model_m_config = model_m.get_config()\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(model_m_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPZePMHf2wDe",
    "colab_type": "text"
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "QrzZxM4h2wDg",
    "colab_type": "code",
    "outputId": "dc7017f1-b4a2-4515-b733-6d761179e015",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 135us/step\n",
      "2000/2000 [==============================] - 0s 127us/step\n",
      "2000/2000 [==============================] - 0s 127us/step\n",
      "\n",
      "-----------\n",
      "Metrics of the models:\n",
      "-----------\n",
      "         \tmale\tfemale\tneuter\n",
      "loss:    \t0.31\t0.20\t0.27\n",
      "acc:    \t0.87\t0.92\t0.89\n",
      "precision:    \t0.82\t0.90\t0.77\n",
      "recall:    \t0.83\t0.92\t0.74\n",
      "fmeasure:    \t0.82\t0.90\t0.74\n"
     ]
    }
   ],
   "source": [
    "scores_m = model_m.evaluate(input_test, output_test_m)\n",
    "scores_f = model_f.evaluate(input_test, output_test_f)\n",
    "scores_n = model_n.evaluate(input_test, output_test_n)\n",
    "\n",
    "print(\"\\n-----------\\nMetrics of the models:\\n-----------\")\n",
    "print(\"         \\tmale\\tfemale\\tneuter\")\n",
    "for i in range(len(scores_m)):\n",
    "    print(\"%s:    \\t%.2f\\t%.2f\\t%.2f\" % (model_m.metrics_names[i], scores_m[i], scores_f[i], scores_n[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9GGGbyVzdiW",
    "colab_type": "text"
   },
   "source": [
    "#### Scikit-learn classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "IyG3_RqJhg8o",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594.0
    },
    "outputId": "7d3ed875-50dc-4ca5-d092-666a60c4a9e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for male classifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.89      0.89      1229\n",
      "          1       0.82      0.84      0.83       771\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2000\n",
      "\n",
      "\n",
      "Classification report for female classifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.92      0.93      1165\n",
      "          1       0.89      0.92      0.91       835\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2000\n",
      "\n",
      "\n",
      "Classification report for neuter classifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.94      0.93      1560\n",
      "          1       0.77      0.74      0.76       440\n",
      "\n",
      "avg / total       0.89      0.89      0.89      2000\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Weighted mean metrics of the three gender classifier models:\n",
      "------------------------------------\n",
      "precision  \t0.8399\n",
      "recall  \t0.85\n",
      "f1-score  \t0.8448\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred_m = model_m.predict(input_test)\n",
    "pred_f = model_f.predict(input_test)\n",
    "pred_n = model_n.predict(input_test)\n",
    "\n",
    "class_pred_m = np.round(pred_m).astype(int).flatten()\n",
    "class_pred_f = np.round(pred_f).astype(int).flatten()\n",
    "class_pred_n = np.round(pred_n).astype(int).flatten()\n",
    "\n",
    "print(\"Classification report for male classifier:\")\n",
    "print(classification_report(output_test_m, class_pred_m))\n",
    "print(\"\\nClassification report for female classifier:\")\n",
    "print(classification_report(output_test_f, class_pred_f))\n",
    "print(\"\\nClassification report for neuter classifier:\")\n",
    "print(classification_report(output_test_n, class_pred_n))\n",
    "\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "# def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "# def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "# def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "# def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precrecf1_m = precision_recall_fscore_support(output_test_m, class_pred_m)\n",
    "precrecf1_f = precision_recall_fscore_support(output_test_f, class_pred_f)\n",
    "precrecf1_n = precision_recall_fscore_support(output_test_n, class_pred_n)\n",
    "\n",
    "prec_rec_f1_support_mfn = []\n",
    "for i in range(3):\n",
    "    try:\n",
    "        val = sum([precrecf1_m[i][1]*precrecf1_m[3][1], precrecf1_f[i][1]*precrecf1_f[3][1], precrecf1_n[i][1]*precrecf1_n[3][1]]) / sum([precrecf1_m[3][1], precrecf1_f[3][1], precrecf1_n[3][1]])\n",
    "    except ZeroDivisionError:\n",
    "        val = 0\n",
    "    prec_rec_f1_support_mfn.append(val)\n",
    "    \n",
    "\n",
    "basic_metrics_labels = [\"precision\", \"recall\", \"f1-score\", \"support\"]\n",
    "print(\"\\n------------------------------------\\nWeighted mean metrics of the three gender classifier models:\\n------------------------------------\")\n",
    "#print(\"\\t\".join(basic_metrics_labels))\n",
    "#basic_metrics_means = []\n",
    "for i in range(3):\n",
    "    #basic_metrics_means.append(round(np.mean([precrecf1_m[i], precrecf1_f[i], precrecf1_n[i]]), 2))\n",
    "    print(\"{}  \\t{}\".format(basic_metrics_labels[i], round(prec_rec_f1_support_mfn[i], 4)))\n",
    "    #print(\"{}  \\t{}\".format(basic_metrics_labels[i], np.mean([precrecf1_m[i], precrecf1_f[i], precrecf1_n[i]])))\n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yt_MdXGY2wDn",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "#### For checking prediction of model for a single noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr64jwao2wCl",
    "colab_type": "text"
   },
   "source": [
    "Encoding a single noun as input to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bWNTithC2wCm",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def encode_noun(noun):\n",
    "    '''Encodes a noun as np array with the required input features (last 4 character info + syllable count).'''\n",
    "    info_for_input = []\n",
    "    for pos in range(4, 0, -1):\n",
    "        for char in char_list:\n",
    "             info_for_input.append(is_char_in_pos(char, -1 * pos, noun))\n",
    "        \n",
    "    info_for_input.append(len(re.findall(vowelregex, noun.lower())))\n",
    "    \n",
    "    return np.array(info_for_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PcNr45Qc2wCp",
    "colab_type": "code",
    "outputId": "351e33b7-ed6c-46cf-b2ef-44aa6dce5d7a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_noun('Hallo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ORSoNHb32wDo",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def single_input(noun, model):\n",
    "    return model.predict( np.array( [encode_noun(noun),] )  )\n",
    "\n",
    "def multiple_input(nounlist, model):\n",
    "    return [model.predict( np.array( [encode_noun(noun),] )  ) for noun in nounlist] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Y7KT7II82wDt",
    "colab_type": "code",
    "outputId": "60d77a04-e66e-44fd-abe5-e069ad00d270",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female model output for 'Katze': [[0.9800426]]\n",
      "Male model output for 'Hund', 'Bär', 'Wasimmer:\n",
      "[array([[0.9406437]], dtype=float32), array([[0.9392669]], dtype=float32), array([[0.5297212]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Female model output for 'Katze':\", single_input('Katze', model_f))\n",
    "\n",
    "print(\"Male model output for 'Hund', 'Bär', 'Wasimmer:\")\n",
    "print(multiple_input(['Hund', 'Bär', 'Wasimmer'], model_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BgFeAhQ9OUV",
    "colab_type": "text"
   },
   "source": [
    "#### User-friendly version for guessing at the gender of a noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5NK3B1KT9MDy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def guess_gender(noun):\n",
    "    gender_outputs = [round(single_input(noun, model)[0][0], 4) for model in [model_m, model_f, model_n]]\n",
    "    print(\"The estimated probabilities for '{}' having the gender...\".format(noun))\n",
    "    print(\"male:\\t{}%\\nfemale:\\t{}%\\nneutral:\\t{}%\\n\".format(int(round(gender_outputs[0]*100)), int(round(gender_outputs[1]*100)), int(round(gender_outputs[2]*100))))\n",
    "    \n",
    "    if noun in nounsandgenders:\n",
    "        genders = ['male', 'female', 'neuter']\n",
    "        noungenders = []\n",
    "        for i in range(3):\n",
    "            if nounsandgenders[noun][i] > .5:\n",
    "                noungenders.append(genders[i])\n",
    "        genderstr = ', '.join(noungenders)\n",
    "        print(\"The actual gender(s) of {} based on Wiktionary:\\t{}\".format(noun, genderstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WtY5PO1x9T95",
    "colab_type": "code",
    "outputId": "35a8d971-164c-4248-99b5-b7317340ac37",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Dielung' having the gender...\n",
      "male:\t1%\n",
      "female:\t99%\n",
      "neutral:\t0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Dielung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sPUD1qW4CREi",
    "colab_type": "code",
    "outputId": "c89acfa0-8403-4400-f875-9a77a70b36ea",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Wiederholung' having the gender...\n",
      "male:\t0%\n",
      "female:\t100%\n",
      "neutral:\t0%\n",
      "\n",
      "The actual gender(s) of Wiederholung based on Wiktionary:\tfemale\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Wiederholung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "TF1DLnQ0CrVF",
    "colab_type": "code",
    "outputId": "c3f06984-81fe-4960-9e4e-665e843f9fab",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Mädchen' having the gender...\n",
      "male:\t9%\n",
      "female:\t1%\n",
      "neutral:\t97%\n",
      "\n",
      "The actual gender(s) of Mädchen based on Wiktionary:\tneuter\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Mädchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tBLs5KFKOcc9",
    "colab_type": "code",
    "outputId": "c93f4aee-9e05-4a6e-e99f-f3fb320ad346",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Sälwiemerchen' having the gender...\n",
      "male:\t8%\n",
      "female:\t2%\n",
      "neutral:\t95%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Sälwiemerchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "G3AukCvaFocJ",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118.0
    },
    "outputId": "b430dc00-bffe-4ee0-f668-15d76e5dce50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Bild' having the gender...\n",
      "male:\t19%\n",
      "female:\t0%\n",
      "neutral:\t97%\n",
      "\n",
      "The actual gender(s) of Bild based on Wiktionary:\tneuter\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Bild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0MJKEtKwirQi",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101.0
    },
    "outputId": "983ef26c-26d2-4aea-cbd9-f009c2a507ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities for 'Anything' having the gender...\n",
      "male:\t40%\n",
      "female:\t3%\n",
      "neutral:\t49%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "guess_gender('Anything')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "German_Gender_Classifiers_ANN.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "Z10Ll3nN2wCf",
    "KvZn0oa6QBXg"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
